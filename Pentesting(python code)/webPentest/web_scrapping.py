import re
import requests
from bs4 import BeautifulSoup

def scrape_bio(url):
    try:
        print(f"[SCRAPER] Scraping bio from: {url}")
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.text, "html.parser")

        # Naive Twitter-like profile bio scraper
        bio = soup.find("meta", {"name": "description"})
        if bio:
            return bio["content"]
        return "Bio not found"
    except Exception as e:
        return f"Scraping error: {e}"

def discover_social_links(url):
    print(f"[DISCOVERY] Trying to find social media links from {url}")
    try:
        res = requests.get(url, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        links = [a['href'] for a in soup.find_all("a", href=True)]

        # Common social patterns
        social_patterns = {
            "facebook": r"facebook\.com",
            "twitter": r"twitter\.com",
            "linkedin": r"linkedin\.com",
            "instagram": r"instagram\.com",
        }

        discovered = []
        for link in links:
            for platform, pattern in social_patterns.items():
                if re.search(pattern, link):
                    discovered.append(link)
        return list(set(discovered))  # Remove duplicates
    except Exception as e:
        print(f"[ERROR] Could not discover social links: {e}")
        return []

